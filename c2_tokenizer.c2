module c2_tokenizer;
import string local;
import stdio local;
import ctype local;
import color;

public type Location struct {   // TODO use SourceMgr
    u32 line;
    u32 column;
}

func const char* Location.str(const Location* loc) {
    local char[32] msg;
    sprintf(msg, "at line %u:%u", loc.line, loc.column);
    return msg;
}

type Keyword struct {
    const char* name;
    TokenKind kind;
    u8 len;
}

// TEMP until C2C allows this
const Keyword*[] keywords = {
    Keywords_a,
    Keywords_b,
    Keywords_c,
    Keywords_d,
    Keywords_e,
    Keywords_f,
    Keywords_g,
    nil,
    Keywords_i,
    nil,
    nil,
    Keywords_l,
    Keywords_m,
    Keywords_n,
    Keywords_o,
    Keywords_p,
    nil,
    Keywords_r,
    Keywords_s,
    Keywords_t,
    Keywords_u,
    Keywords_v,
    Keywords_w,
    nil,
    nil,
    nil,
}

const Keyword[] Keywords_a = {
    { "as", TokenKind.KW_as, 2 },
    { "asm", TokenKind.KW_asm, 3 },
    { "auto", TokenKind.KW_auto, 4, },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_b = {
    { "bool", TokenKind.KW_bool, 4 },
    { "break", TokenKind.KW_break, 5 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_c = {
    { "case", TokenKind.KW_case, 4 },
    { "cast", TokenKind.KW_cast, 4 },
    { "char", TokenKind.KW_char, 4 },
    { "const", TokenKind.KW_const, 5 },
    { "continue", TokenKind.KW_continue, 8 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_d = {
    { "default", TokenKind.KW_default, 8 },
    { "do", TokenKind.KW_do, 2 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_e = {
    { "elemsof", TokenKind.KW_elemsof, 7 },
    { "else", TokenKind.KW_else, 4 },
    { "enum_max", TokenKind.KW_enum_max, 8 },
    { "enum_min", TokenKind.KW_enum_min, 8 },
    { "enum", TokenKind.KW_enum, 4 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_f = {
    { "f32", TokenKind.KW_f32, 3 },
    { "f64", TokenKind.KW_f64, 3 },
    { "fallthrough", TokenKind.KW_fallthrough, 11 },
    { "false", TokenKind.KW_false, 5 },
    { "for", TokenKind.KW_for, 3 },
    { "func", TokenKind.KW_func, 4 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_g = {
    { "goto", TokenKind.KW_goto, 4 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_i = {
    { "i16", TokenKind.KW_i16, 3 },
    { "i32", TokenKind.KW_i32, 3 },
    { "i64", TokenKind.KW_i64, 3 },
    { "i8", TokenKind.KW_i8, 2 },
    { "if", TokenKind.KW_if, 2 },
    { "import", TokenKind.KW_import, 6 },
    { "isize", TokenKind.KW_isize, 5 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_l = {
    { "local", TokenKind.KW_local, 5 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_m = {
    { "module", TokenKind.KW_module, 6 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_n = {
    { "nil", TokenKind.KW_nil, 3 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_o = {
    { "offsetof", TokenKind.KW_offsetof, 8 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_p = {
    { "public", TokenKind.KW_public, 6 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_r = {
    { "reg16", TokenKind.KW_reg16, 5 },
    { "reg32", TokenKind.KW_reg32, 5 },
    { "reg64", TokenKind.KW_reg64, 5 },
    { "reg8", TokenKind.KW_reg8, 4 },
    { "return", TokenKind.KW_return, 6 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_s = {
    { "sizeof", TokenKind.KW_sizeof, 6 },
    { "sswitch", TokenKind.KW_sswitch, 7 },
    { "static_assert", TokenKind.KW_static_assert, 13 },
    { "struct", TokenKind.KW_struct, 6 },
    { "switch", TokenKind.KW_switch, 6 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_t = {
    { "to_container", TokenKind.KW_to_container, 12 },
    { "true", TokenKind.KW_true, 4 },
    { "type", TokenKind.KW_type, 4 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_u = {
    { "u16", TokenKind.KW_u16, 3 },
    { "u32", TokenKind.KW_u32, 3 },
    { "u64", TokenKind.KW_u64, 3 },
    { "u8", TokenKind.KW_u8, 2 },
    { "union", TokenKind.KW_union, 5 },
    { "usize", TokenKind.KW_usize, 5 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_v = {
    { "void", TokenKind.KW_void, 4 },
    { "volatile", TokenKind.KW_volatile, 8 },
    { nil, TokenKind.None, 0 },
}
const Keyword[] Keywords_w = {
    { "while", TokenKind.KW_while, 5 },
    { nil, TokenKind.None, 0 },
}

// TODO order by frequency
public type TokenKind enum u8 {
    None,
    Identifier,
    NumberLiteral,
    CharLiteral,
    StringLiteral,
    LParen,
    RParen,
    LSquare,
    RSquare,
    LBrace,
    RBrace,
    Exclaim,
    ExclaimEqual,
    Star,
    StarEqual,
    Amp,
    AmpAmp,
    AmpEqual,
    Pipe,
    PipePipe,
    PipeEqual,
    Equal,
    EqualEqual,
    Semicolon,
    Colon,
    At,
    Caret,
    CaretEqual,
    Question,
    Dot,
    Ellipsis,
    Comma,
    Plus,
    PlusPlus,
    PlusEqual,
    Minus,
    MinusMinus,
    MinusEqual,
    Tilde,
    Slash,
    SlashEqual,
    Percent,
    PercentEqual,
    Less,
    LessLess,
    LessEqual,
    LessLessEqual,
    Greater,
    GreaterGreater,
    GreaterEqual,
    GreaterGreaterEqual,
    KW_as,
    KW_asm,
    KW_auto,
    KW_bool,
    KW_break,
    KW_case,
    KW_cast,
    KW_char,
    KW_const,
    KW_continue,
    KW_default,
    KW_do,
    KW_elemsof,
    KW_else,
    KW_enum_max,
    KW_enum_min,
    KW_enum,
    KW_f32,
    KW_f64,
    KW_fallthrough,
    KW_false,
    KW_for,
    KW_func,
    KW_goto,
    KW_i16,
    KW_i32,
    KW_i64,
    KW_i8,
    KW_if,
    KW_import,
    KW_isize,
    KW_local,
    KW_module,
    KW_nil,
    KW_offsetof,
    KW_public,
    KW_reg16,
    KW_reg32,
    KW_reg64,
    KW_reg8,
    KW_return,
    KW_sizeof,
    KW_sswitch,
    KW_static_assert,
    KW_struct,
    KW_switch,
    KW_to_container,
    KW_true,
    KW_type,
    KW_u16,
    KW_u32,
    KW_u64,
    KW_u8,
    KW_union,
    KW_usize,
    KW_void,
    KW_volatile,
    KW_while,
    Eof,
    Error,
}

// NOTE: keep in sync with TokenKind
const char*[] token_names = {
    "none",
    "identifier",
    "number",
    "char",
    "string",
    "(",
    ")",
    "[",
    "]",
    "{",
    "}",
    "!",
    "!=",
    "*",
    "*=",
    "&",
    "&&",
    "&=",
    "|",
    "||",
    "|=",
    "=",
    "==",
    ";",
    ":",
    "@",
    "^",
    "^=",
    "?",
    ".",
    "...",
    ",",
    "+",
    "++",
    "+=",
    "-",
    "--",
    "-=",
    "~",
    "/",
    "/=",
    "%",
    "%=",
    "<",
    "<<",
    "<=",
    "<<=",
    ">",
    ">>",
    ">=",
    ">>=",
    "as",
    "asm",
    "auto",
    "bool",
    "break",
    "case",
    "cast",
    "char",
    "const",
    "continue",
    "default",
    "do",
    "elemsof",
    "else",
    "enum_max",
    "enum_min",
    "enum",
    "f32",
    "f64",
    "falltrhough",
    "false",
    "for",
    "func",
    "goto",
    "i16",
    "i32",
    "i64",
    "i8",
    "if",
    "import",
    "isize",
    "local",
    "module",
    "nil",
    "offsetof",
    "public",
    "reg16",
    "reg32",
    "reg64",
    "reg8",
    "return",
    "sizeof",
    "sswitch",
    "static_assert",
    "struct",
    "switch",
    "to_container",
    "true",
    "type",
    "u16",
    "u32",
    "u64",
    "u8",
    "union",
    "usize",
    "void",
    "volatile",
    "while",
    "eof",
    "error",
}

//static_assert(elemsof(TokenKind) == elemsof(token_names), "should be the same");

type Action enum u8 {
    INVALID = 0,
    TABSPACE,
    IDENT_OR_KEYWORD,
    IDENT,
    DIGIT,
    LPAREN,
    RPAREN,
    LSQUARE,
    RSQUARE,
    NEWLINE,
    EXCLAIM,
    DQUOTE,
    SQUOTE,
    STAR,
    PLUS,
    MINUS,
    COMMA,
    DOT,
    PERCENT,
    SLASH,
    COLON,
    SEMI_COLON,
    LESS,
    EQUAL,
    GREATER,
    QUESTION,
    AT,
    AMP,
    CARET,
    LBRACE,
    RBRACE,
    PIPE,
    TILDE,
    CR,
    EOF,
}

u8[128] char_lookup = {
// 0 - 15
   [  0]  = Action.EOF,
   ['\t'] = Action.TABSPACE,
   ['\n'] = Action.NEWLINE,
   ['\r'] = Action.CR,
// 16 - 31
// 32 - 47
    [' '] = Action.TABSPACE,
    ['!'] = Action.EXCLAIM,
    ['"'] = Action.DQUOTE,
// #
    ['%'] = Action.PERCENT,
    ['&'] = Action.AMP,
   ['\''] = Action.SQUOTE,
    ['('] = Action.LPAREN,
    [')'] = Action.RPAREN,
    ['*'] = Action.STAR,
    ['+'] = Action.PLUS,
    [','] = Action.COMMA,
    ['-'] = Action.MINUS,
    ['.'] = Action.DOT,
    ['/'] = Action.SLASH,
// 48 - 63
    ['0'] = Action.DIGIT,
    ['1'] = Action.DIGIT,
    ['2'] = Action.DIGIT,
    ['3'] = Action.DIGIT,
    ['4'] = Action.DIGIT,
    ['5'] = Action.DIGIT,
    ['6'] = Action.DIGIT,
    ['7'] = Action.DIGIT,
    ['8'] = Action.DIGIT,
    ['9'] = Action.DIGIT,
    [':'] = Action.COLON,
    [';'] = Action.SEMI_COLON,
    ['<'] = Action.LESS,
    ['='] = Action.EQUAL,
    ['>'] = Action.GREATER,
    ['?'] = Action.QUESTION,
// 64 - 79
    ['@'] = Action.AT,
    ['A'] = Action.IDENT,
    ['B'] = Action.IDENT,
    ['C'] = Action.IDENT,
    ['D'] = Action.IDENT,
    ['E'] = Action.IDENT,
    ['F'] = Action.IDENT,
    ['G'] = Action.IDENT,
    ['H'] = Action.IDENT,
    ['I'] = Action.IDENT,
    ['J'] = Action.IDENT,
    ['K'] = Action.IDENT,
    ['L'] = Action.IDENT,
    ['M'] = Action.IDENT,
    ['N'] = Action.IDENT,
    ['O'] = Action.IDENT,
// 80 - 95
    ['P'] = Action.IDENT,
    ['Q'] = Action.IDENT,
    ['R'] = Action.IDENT,
    ['S'] = Action.IDENT,
    ['T'] = Action.IDENT,
    ['U'] = Action.IDENT,
    ['V'] = Action.IDENT,
    ['W'] = Action.IDENT,
    ['X'] = Action.IDENT,
    ['Y'] = Action.IDENT,
    ['Z'] = Action.IDENT,
    ['['] = Action.LSQUARE,
    // '\'
    [']'] = Action.RSQUARE,
    ['^'] = Action.CARET,
    //'_'
// 96 - 111
    ['a'] = Action.IDENT_OR_KEYWORD,
    ['b'] = Action.IDENT_OR_KEYWORD,
    ['c'] = Action.IDENT_OR_KEYWORD,
    ['d'] = Action.IDENT_OR_KEYWORD,
    ['e'] = Action.IDENT_OR_KEYWORD,
    ['f'] = Action.IDENT_OR_KEYWORD,
    ['g'] = Action.IDENT_OR_KEYWORD,
    ['h'] = Action.IDENT,
    ['i'] = Action.IDENT_OR_KEYWORD,
    ['j'] = Action.IDENT,
    ['k'] = Action.IDENT,
    ['l'] = Action.IDENT_OR_KEYWORD,
    ['m'] = Action.IDENT_OR_KEYWORD,
    ['n'] = Action.IDENT_OR_KEYWORD,
    ['o'] = Action.IDENT_OR_KEYWORD,
// 112 -] 127
    ['p'] = Action.IDENT_OR_KEYWORD,
    ['q'] = Action.IDENT,
    ['r'] = Action.IDENT_OR_KEYWORD,
    ['s'] = Action.IDENT_OR_KEYWORD,
    ['t'] = Action.IDENT_OR_KEYWORD,
    ['u'] = Action.IDENT_OR_KEYWORD,
    ['v'] = Action.IDENT_OR_KEYWORD,
    ['w'] = Action.IDENT_OR_KEYWORD,
    ['x'] = Action.IDENT,
    ['y'] = Action.IDENT,
    ['z'] = Action.IDENT,
    ['{'] = Action.LBRACE,
    ['|'] = Action.PIPE,
    ['}'] = Action.RBRACE,
    ['~'] = Action.TILDE,
}


public func const char* Token.str(const Token* tok) {
    return token_names[tok.kind];
}

public func const char* kind2str(TokenKind kind) {
    return token_names[kind];
}

func bool identifier_initial_char(char c) {
    if (c >= 'a' && c <= 'z') return true;
    if (c >= 'A' && c <= 'Z') return true;
    return false;
}

func bool identifier_char(char c) {
    // TODO use lookup table (same as for initial?)
    if (c >= 'a' && c <= 'z') return true;
    if (c >= 'A' && c <= 'Z') return true;
    if (c >= '0' && c <= '9') return true;
    if (c == '_') return true;
    return false;
}

func const Keyword* check_keyword(const char* cp) {
    const Keyword* table = keywords[*cp - 'a'];
    u32 i = 0;
    while (table[i].name) {
        const char* word = cp;
        const char* kw = table[i].name;
        u32 idx = 0;
        while (1) {
            char a = kw[idx];
            char b = word[idx];
            if (a == 0) {
                if (!isalpha(b)) return &table[i];
                break;
            }
            if (a != b) {
                if (b < a) return nil;
                break;
            }
            idx++;
        }
        i++;
    }

    return nil;
}

public type Token struct {
    Location loc;
    TokenKind kind;
    union {
        const char* error_msg;  // ERROR
        const char* text_value; // Identifier, NumberLiteral
        char char_value; // CharLiteral
    }
    bool more;
}

public func void Token.init(Token* tok) {
    tok.kind = TokenKind.None;
    tok.more = true;
}

public func void Token.dump(const Token* tok) {
    if (tok.kind >= TokenKind.KW_as && tok.kind <= TokenKind.KW_while) {
        printf("%s%10s%s   %u:%u\n", color.Green, tok.str(), color.Normal, tok.loc.line, tok.loc.column);
        return;
    }
    printf("%10s   %u:%u", tok.str(), tok.loc.line, tok.loc.column);
    switch (tok.kind) {
    case TokenKind.Identifier:
        printf("  %s%s%s", color.Cyan, tok.text_value, color.Normal);
        break;
    case TokenKind.NumberLiteral:
        printf("  %s%s%s", color.Cyan, tok.text_value, color.Normal);
        break;
    case TokenKind.Error:
        printf("  %s%s%s", color.Red, tok.error_msg, color.Normal);
        break;
    default:
        break;
    }
    printf("\n");
}

public type Alloc_fn func const char* (void* arg, const char* value, u32 len);

public type Tokenizer struct {
    const char* cur;
    Location loc;
    const char* input_start;
    char* error_msg;

    Token next;

    Alloc_fn alloc;
    void* alloc_arg;
    //Data* data;   // TODO for mem-allocs
}

public func void Tokenizer.init(Tokenizer* t, const char* input, /*Data* d,*/ char* error_msg, Alloc_fn alloc, void* arg) {
    memset(t, 0, sizeof(Tokenizer));
    t.cur = input;
    t.input_start = input;
    t.loc.line = 1;
    t.loc.column = 1;
    t.error_msg = error_msg;
    //t.data = d;
    t.alloc = alloc;
    t.alloc_arg = arg;
    t.next.kind = TokenKind.None;
}

public func void Tokenizer.lex(Tokenizer* t, Token* result) {
    if (t.next.kind != TokenKind.None) {
        memcpy(result, &t.next, sizeof(Token));
        t.next.kind = TokenKind.None;
        return;
    }

    while (1) {
        Action act = char_lookup[*t.cur];
        switch (act) {
        case Action.INVALID:
            sprintf(t.error_msg, "invalid char '%c' %s", *t.cur, t.loc.str());
            t.error(result);
            return;
        case Action.TABSPACE:
            t.cur++;
            t.loc.column++;
            continue;
        case Action.IDENT_OR_KEYWORD:
            result.loc = t.loc;
            const Keyword* kw = check_keyword(t.cur);
            if (kw) {
                result.kind = kw.kind;
                t.cur += kw.len;
                t.loc.column += kw.len;
            } else {
                t.lex_identifier(result);
            }
            return;
        case Action.IDENT:
            t.lex_identifier(result);
            return;
        case Action.DIGIT:
            t.lex_number(result);
            return;
        case Action.LPAREN:
            result.loc = t.loc;
            result.kind = TokenKind.LParen;
            t.cur++;
            t.loc.column++;
            return;
        case Action.RPAREN:
            result.loc = t.loc;
            result.kind = TokenKind.RParen;
            t.cur++;
            t.loc.column++;
            return;
        case Action.LSQUARE:
            result.loc = t.loc;
            result.kind = TokenKind.LSquare;
            t.cur++;
            t.loc.column++;
            return;
        case Action.RSQUARE:
            result.loc = t.loc;
            result.kind = TokenKind.RSquare;
            t.cur++;
            t.loc.column++;
            return;
        case Action.NEWLINE:
            t.cur++;
            t.loc.line++;
            t.loc.column = 1;
            continue;
        case Action.EXCLAIM:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '=') {
                result.kind = TokenKind.ExclaimEqual;
                t.cur++;
                t.loc.column++;
            } else {
                result.kind = TokenKind.Exclaim;
            }
            return;
        case Action.DQUOTE:
            t.lex_string_literal(result);
            return;
        case Action.SQUOTE:
            t.lex_char_literal(result);
            return;
        case Action.STAR:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '=') {
                result.kind = TokenKind.StarEqual;
                t.cur++;
                t.loc.column++;
            } else {
                result.kind = TokenKind.Star;
            }
            return;
        case Action.PLUS:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '+') {
                t.cur++;
                t.loc.column++;
                result.kind = TokenKind.PlusPlus;
                return;
            }
            if (*t.cur == '=') {
                t.cur++;
                t.loc.column++;
                result.kind = TokenKind.PlusEqual;
                return;
            }
            result.kind = TokenKind.Plus;
            return;
        case Action.MINUS:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '-') {
                t.cur++;
                t.loc.column++;
                result.kind = TokenKind.MinusMinus;
                return;
            }
            if (*t.cur == '=') {
                t.cur++;
                t.loc.column++;
                result.kind = TokenKind.MinusEqual;
                return;
            }
            result.kind = TokenKind.Minus;
            return;
        case Action.COMMA:
            result.loc = t.loc;
            result.kind = TokenKind.Comma;
            t.cur++;
            t.loc.column++;
            return;
        case Action.DOT:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (t.cur[0] == '.' && t.cur[1] == '.') {
                t.cur += 2;
                t.loc.column += 2;
                result.kind = TokenKind.Ellipsis;
            } else {
                result.kind = TokenKind.Dot;
            }
            return;
        case Action.PERCENT:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '=') {
                result.kind = TokenKind.PercentEqual;
                t.cur++;
                t.loc.column++;
                return;
            }
            result.kind = TokenKind.Percent;
            return;
        case Action.SLASH:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '=') {
                result.kind = TokenKind.SlashEqual;
                t.cur++;
                t.loc.column++;
                return;
            }
            if (*t.cur == '/') {
                t.skip_line_comment();
                // TODO sometimes have TokenKind.Comment
                continue;
            }
            result.kind = TokenKind.Slash;
            return;
        case Action.COLON:
            result.loc = t.loc;
            result.kind = TokenKind.Colon;
            t.cur++;
            t.loc.column++;
            return;
        case Action.SEMI_COLON:
            result.loc = t.loc;
            result.kind = TokenKind.Semicolon;
            t.cur++;
            t.loc.column++;
            return;
        case Action.LESS:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '=') {
                t.cur++;
                t.loc.column++;
                result.kind = TokenKind.LessEqual;
                return;
            }
            if (*t.cur == '<') {
                t.cur++;
                t.loc.column++;
                if (*t.cur == '=') {
                    t.cur++;
                    t.loc.column++;
                    result.kind = TokenKind.LessLessEqual;
                }
                result.kind = TokenKind.LessLess;
                return;
            }
            result.kind = TokenKind.Less;
            return;
        case Action.EQUAL:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '=') {
                result.kind = TokenKind.EqualEqual;
                t.cur++;
                t.loc.column++;
            } else {
                result.kind = TokenKind.Equal;
            }
            return;
        case Action.GREATER:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '=') {
                t.cur++;
                t.loc.column++;
                result.kind = TokenKind.GreaterEqual;
                return;
            }
            if (*t.cur == '>') {
                t.cur++;
                t.loc.column++;
                if (*t.cur == '=') {
                    t.cur++;
                    t.loc.column++;
                    result.kind = TokenKind.GreaterGreaterEqual;
                }
                result.kind = TokenKind.GreaterGreater;
                return;
            }
            result.kind = TokenKind.Greater;
            return;
        case Action.QUESTION:
            result.loc = t.loc;
            result.kind = TokenKind.Question;
            t.cur++;
            t.loc.column++;
            return;
        case Action.AT:
            result.loc = t.loc;
            result.kind = TokenKind.At;
            t.cur++;
            t.loc.column++;
            return;
        case Action.AMP:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '&') {
                result.kind = TokenKind.AmpAmp;
                t.cur++;
                t.loc.column++;
                return;
            }
            if (*t.cur == '=') {
                result.kind = TokenKind.AmpEqual;
                t.cur++;
                t.loc.column++;
                return;
            }
            result.kind = TokenKind.Amp;
            return;
        case Action.CARET:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '=') {
                t.cur++;
                t.loc.column++;
                result.kind = TokenKind.CaretEqual;
                return;
            }
            result.kind = TokenKind.Caret;
            return;
        case Action.LBRACE:
            result.loc = t.loc;
            result.kind = TokenKind.LBrace;
            t.cur++;
            t.loc.column++;
            return;
        case Action.RBRACE:
            result.loc = t.loc;
            result.kind = TokenKind.RBrace;
            t.cur++;
            t.loc.column++;
            return;
        case Action.PIPE:
            result.loc = t.loc;
            t.cur++;
            t.loc.column++;
            if (*t.cur == '|') {
                result.kind = TokenKind.PipePipe;
                t.cur++;
                t.loc.column++;
                return;
            }
            if (*t.cur == '=') {
                result.kind = TokenKind.PipeEqual;
                t.cur++;
                t.loc.column++;
                return;
            }
            result.kind = TokenKind.Pipe;
            return;
        case Action.TILDE:
            result.loc = t.loc;
            result.kind = TokenKind.Tilde;
            t.cur++;
            t.loc.column++;
            return;
        case Action.CR:
            t.cur++;
            if (*t.cur != '\n') {
                sprintf(t.error_msg, "unexpected char 0x%02X %s", *t.cur, t.loc.str());
                t.error(result);
                return;
            }
            t.cur++;
            t.loc.line++;
            t.loc.column = 1;
            return;
        case Action.EOF:
            result.loc = t.loc;
            result.kind = TokenKind.Eof;
            result.more = false;
            return;
        }
    }
}

public func Token* Tokenizer.lex_next(Tokenizer* t) {
    if (t.next.kind == TokenKind.None) t.lex(&t.next);

    return &t.next;
}

func void Tokenizer.error(Tokenizer* t, Token* result) {
    result.loc = t.loc;
    result.kind = TokenKind.Error;
    // TODO end location print here
    result.error_msg = t.error_msg;
    result.more = false;
}

func void Tokenizer.lex_identifier(Tokenizer* t, Token* result) {
    // NOTE: result.loc are already set
    result.kind = TokenKind.Identifier;
    result.loc = t.loc;
    const char* start = t.cur;
    const char* end = t.cur + 1;
    while (identifier_char(*end)) end++;

    u32 len = cast<u32>(end - start);
    t.cur += len;
    t.loc.column += len;
    result.text_value = t.alloc(t.alloc_arg, start, len);
}

func void Tokenizer.lex_number(Tokenizer* t, Token* result) {
    result.kind = TokenKind.NumberLiteral;
    result.loc = t.loc;
    const char* start = t.cur;
    const char* end = t.cur + 1;
    while (isdigit(*end)) end++;

    u32 len = cast<u32>(end - start);
    t.cur += len;
    t.loc.column += len;
    result.text_value = t.alloc(t.alloc_arg, start, len);
}

func void Tokenizer.lex_char_literal(Tokenizer* t, Token* result) {
    result.kind = TokenKind.CharLiteral;
    result.loc = t.loc;

    if (t.cur[1] == '\\') {
        t.cur++;
        t.loc.column++;
        switch (t.cur[1]) {
        case 'n':
            result.char_value = '\n';
            break;
        case 'r':
            result.char_value = '\r';
            break;
        case 't':
            result.char_value = '\t';
            break;
        case '\\':
            result.char_value = '\\';
            break;
        case '\'':
            result.char_value = '\'';
            break;
        default:
            sprintf(t.error_msg, "unknown escape sequence \\%c %s", t.cur[1], t.loc.str());
            t.error(result);
            return;
        }
    } else {
        result.char_value = t.cur[1];
    }

    if (t.cur[2] != '\'') {
        sprintf(t.error_msg, "missing terminated ' character %s", t.loc.str());
        t.error(result);
        return;
    }

    t.cur += 3;
    t.loc.column += 3;
}

func void Tokenizer.lex_string_literal(Tokenizer* t, Token* result) {
    result.kind = TokenKind.StringLiteral;
    result.loc = t.loc;
    t.cur++;
    const char* start = t.cur;
    u32 len;

    while (1) {
        switch (*t.cur) {
        case 0: fallthrough;
        case '\r': fallthrough;
        case '\n':
            t.loc.column += (t.cur - start);
             sprintf(t.error_msg, "unterminated string %s", t.loc.str());
             t.error(result);
             return;
        case '"':
            goto out;
            break;
        default:
            t.cur++;
            break;
        }
    }
out:
    len = cast<u32>(t.cur - start);
    t.cur++;    // skip end delimiter
    result.text_value = t.alloc(t.alloc_arg, start, len);
    t.loc.column += len + 2;  // add quotes
}

func void Tokenizer.skip_line_comment(Tokenizer* t) {
    t.cur += 2;

    const char* start = t.cur;
    const char* end = start;
    while (*end) {
        if (*end == '\r' || *end == '\n') break;
        end++;
    }

    u32 len = cast<u32>(end - start);
    t.cur += len;
    t.loc.column += len;
}

